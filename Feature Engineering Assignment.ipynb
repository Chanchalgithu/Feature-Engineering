{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3695ef-5dc8-4e9f-be61-5055e9490d66",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Assignment Questions\n",
    "\n",
    "# 1. What is a parameter?\n",
    "\n",
    "In feature engineering, a parameter is a value that helps decide how to change or process a feature (column) in the data.\n",
    "\n",
    "ðŸ”¹Simple Example:\n",
    "\n",
    "If you divide ages into groups:\n",
    "\n",
    "    pd.cut(df['age'], bins=3)\n",
    "    \n",
    "Here, bins=3 is a parameter â€“ it tells how many groups to make.\n",
    "\n",
    "In scaling, the min and max values used to scale features are parameters.\n",
    "\n",
    "# 2. What is correlation? What does Negative Correlation mean?\n",
    "\n",
    "### What is Correlation?\n",
    "\n",
    "**Correlation** is a statistical measure that shows how two variables are related.  \n",
    "It tells whether an increase in one variable will cause an increase or decrease in another.\n",
    "\n",
    "---\n",
    "\n",
    "### What does Negative Correlation mean?\n",
    "\n",
    "**Negative correlation** means when one variable increases, the other decreases.\n",
    "\n",
    "**Example:**\n",
    "- If exercise time increases, weight decreases.\n",
    "- So, exercise time and weight have a negative correlation.\n",
    "\n",
    "---\n",
    "\n",
    "### Correlation Values:\n",
    "\n",
    "- `+1` â†’ Strong positive correlation  \n",
    "- `0` â†’ No correlation  \n",
    "- `-1` â†’ Strong negative correlation\n",
    "\n",
    "# 3. Define Machine Learning. What are the main components in Machine Learning?\n",
    "\n",
    "### Classic Definition (Tom Mitchell):\n",
    "\n",
    "> A computer program is said to learn from **experience (E)** with respect to some **task (T)** and **performance measure (P)** if its performance at the task improves with experience.\n",
    "\n",
    "- **T (Task):** What the model is trying to do (e.g., classify emails as spam or not).\n",
    "- **P (Performance):** How well it is doing (e.g., accuracy, precision).\n",
    "- **E (Experience):** The data it learns from (e.g., past emails and their labels).\n",
    "\n",
    "---\n",
    "\n",
    "### Main Components of Machine Learning\n",
    "\n",
    "1. **Data**\n",
    "   - The source of experience for the model.\n",
    "   - Example: Customer data, images, text, etc.\n",
    "\n",
    "2. **Features**\n",
    "   - Input variables used for prediction (columns in a dataset).\n",
    "\n",
    "3. **Model**\n",
    "   - A mathematical structure that finds patterns in data.\n",
    "\n",
    "4. **Training**\n",
    "   - The process of feeding data to the model so it can learn.\n",
    "\n",
    "5. **Task**\n",
    "   - The goal the model is trying to accomplish.\n",
    "   - Example: Predicting house prices.\n",
    "\n",
    "6. **Performance**\n",
    "   - The metric to evaluate model success.\n",
    "   - Example: Accuracy, RMSE, F1 Score.\n",
    "\n",
    "7. **Experience**\n",
    "   - Historical data used to improve performance.\n",
    "\n",
    "8. **Loss Function**\n",
    "   - Measures how far off the predictions are from actual values.\n",
    "\n",
    "9. **Optimization Algorithm**\n",
    "   - Algorithm to reduce loss and improve accuracy (e.g., Gradient Descent).\n",
    "\n",
    "10. **Prediction**\n",
    "    - Using the trained model to make future decisions.\n",
    "\n",
    "---    \n",
    "# 4. How does loss value help in determining whether the model is good or not?\n",
    "\n",
    "**Loss value** is a number that shows **how far off** the modelâ€™s predictions are from the actual values.\n",
    "\n",
    "- A **low loss** means the modelâ€™s predictions are **close to the actual results** â†’ Good model.\n",
    "- A **high loss** means the predictions are **far from the actual results** â†’ Poor model.\n",
    "\n",
    "---\n",
    "\n",
    "### Why is it important?\n",
    "\n",
    "- During training, the model tries to **minimize the loss** using optimization techniques.\n",
    "- **Loss guides learning**: It helps the model improve step by step by adjusting weights.\n",
    "- It tells us **how well the model is learning** from the data.\n",
    "\n",
    "---\n",
    "\n",
    "### In short:\n",
    "\n",
    "> **Lower the loss, better the modelâ€™s performance.**\n",
    "\n",
    "# 5. What are continuous and categorical variables?                              \n",
    "\n",
    "#### ðŸ”¹ Continuous Variables:\n",
    "- Variables that can take **any numerical value** within a range.\n",
    "- They are **measurable** and often include decimal values.\n",
    "\n",
    "**Examples:**\n",
    "- Height (in cm)\n",
    "- Weight (in kg)\n",
    "- Temperature (in Â°C)\n",
    "- Price (in â‚¹)\n",
    "\n",
    "#### ðŸ”¹ Categorical Variables:\n",
    "- Variables that represent **categories or groups**.\n",
    "- They are **not numeric** (or are treated as labels even if numbers are used).\n",
    "\n",
    "**Examples:**\n",
    "- Gender (Male, Female)\n",
    "- Color (Red, Blue, Green)\n",
    "- Education level (High School, College)\n",
    "- Zip code (even if numbers, they are categories)\n",
    "\n",
    "---\n",
    "\n",
    "###  In short:\n",
    "\n",
    "| Type             | Description                     | Examples                        |\n",
    "|------------------|----------------------------------|----------------------------------|\n",
    "| Continuous        | Numeric, measurable              | Height, weight, salary           |\n",
    "| Categorical       | Labels or categories             | Gender, city, product type       |\n",
    "\n",
    "# 6. How do we handle categorical variables in Machine Learning? What are the common techniques?   \n",
    "\n",
    "### How do we handle Categorical Variables in Machine Learning?\n",
    "\n",
    "Categorical variables must be **converted into numerical form** before they can be used in most machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Common Techniques to Handle Categorical Variables:\n",
    "\n",
    " 1. **Label Encoding**\n",
    "- Converts each category into a **unique number**.\n",
    "- Best for **ordinal data** (where order matters).\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['category_encoded'] = le.fit_transform(df['category'])\n",
    "\n",
    "2. **One-Hot Encoding**\n",
    "\n",
    " - Creates a separate binary column for each category.\n",
    "\n",
    " - Best for nominal data (no order).\n",
    "\n",
    "pd.get_dummies(df['category'])\n",
    "\n",
    " 3. **Ordinal Encoding**\n",
    "\n",
    " - Assigns ordered numbers to categories manually.\n",
    "\n",
    " - Useful when categories have natural order.\n",
    "     \n",
    "education_levels = {'High School': 1, 'Bachelor': 2, 'Master': 3}\n",
    "df['education_encoded'] = df['education'].map(education_levels)\n",
    "\n",
    " 4. **Target Encoding (Mean Encoding)**\n",
    "\n",
    " - Replaces categories with the mean of the target variable.\n",
    "\n",
    " - Useful for high-cardinality features in supervised learning.\n",
    "\n",
    "# Example: Average salary per job title\n",
    "df['job_encoded'] = df.groupby('job')['salary'].transform('mean')\n",
    "\n",
    " 5. **Frequency Encoding**\n",
    "\n",
    "Replace each category with how frequently it appears.\n",
    "\n",
    "freq = df['category'].value_counts()\n",
    "df['category_encoded'] = df['category'].map(freq)\n",
    "\n",
    "\n",
    "# 7.What do you mean by training and testing a dataset?\n",
    "\n",
    "In Machine Learning, a dataset is usually **split into two parts**: **training** and **testing** datasets.\n",
    "\n",
    "### ðŸ”¹ Training Dataset:\n",
    "- Used to **train the model**.\n",
    "- The model **learns patterns** from this data.\n",
    "- It includes both input features and the correct output (label).\n",
    "\n",
    "**Example:**  \n",
    "Model learns how hours studied affects exam score.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Testing Dataset:\n",
    "- Used to **evaluate the modelâ€™s performance**.\n",
    "- This data is **not shown** to the model during training.\n",
    "- Helps check if the model can make accurate predictions on new/unseen data.\n",
    "\n",
    "**Example:**  \n",
    "Test if the model can predict exam scores for new students.\n",
    "\n",
    "---\n",
    "\n",
    "###  In short:\n",
    "> - **Training set**: For learning  \n",
    "> - **Testing set**: For checking accuracy  \n",
    "> Good models perform well on **both** training and testing data.\n",
    "\n",
    "\n",
    "# 8. What is sklearn.preprocessing?\n",
    "\n",
    "`sklearn.preprocessing` is a **module in Scikit-learn (sklearn)** that provides tools to **prepare and transform data** before using it in machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Why is it used?\n",
    "\n",
    "Most ML models work better when data is:\n",
    "- Scaled properly\n",
    "- Encoded correctly\n",
    "- Cleaned of missing or inconsistent values\n",
    "\n",
    "`sklearn.preprocessing` helps with these tasks.\n",
    "\n",
    "---\n",
    "\n",
    "###  Common Functions in `sklearn.preprocessing`:\n",
    "\n",
    "| Function                    | Purpose                                    |\n",
    "|-----------------------------|--------------------------------------------|\n",
    "| `StandardScaler()`          | Scales features to have mean 0, std 1     |\n",
    "| `MinMaxScaler()`            | Scales data between 0 and 1                |\n",
    "| `LabelEncoder()`            | Converts labels (categories) into numbers  |\n",
    "| `OneHotEncoder()`           | Converts categories into binary columns    |\n",
    "| `Binarizer()`               | Converts numerical values to 0 or 1\n",
    "\n",
    "\n",
    "# 9. What is a Test set?\n",
    "\n",
    "### What is a Test Set?\n",
    "\n",
    "A **test set** is a part of the dataset that is **used to evaluate** the performance of a machine learning model **after training**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Purpose:\n",
    "- To check how well the model performs on **unseen data**.\n",
    "- Helps to measure the modelâ€™s **accuracy, precision, recall**, etc.\n",
    "- It is **not used** during training.\n",
    "\n",
    "---\n",
    "\n",
    "###  Example:\n",
    "If you have 1000 data points:\n",
    "- **80% (800)** â†’ used for training (train set)\n",
    "- **20% (200)** â†’ used for testing (test set)\n",
    "\n",
    "---\n",
    "\n",
    "###  In short:\n",
    "> A **test set** is used to **check if the model works well on new data** that it hasnâ€™t seen before.\n",
    "\n",
    "# 10. How do we split data for model fitting (training and testing) in Python? \n",
    " # How do you approach a Machine Learning problem?                      \n",
    "\n",
    "### How do we split data for model fitting (training and testing) in Python?\n",
    "\n",
    "We use `train_test_split()` from `sklearn.model_selection`.\n",
    "\n",
    "####  Example:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "                      \n",
    "X = input features\n",
    "\n",
    "y = target/output\n",
    "\n",
    "test_size=0.2 means 80% for training, 20% for testing\n",
    "\n",
    "# How do you approach a Machine Learning problem?\n",
    "\n",
    "Easy Steps:\n",
    " \n",
    "1.Understand the problem â€“ What are you trying to predict?\n",
    "\n",
    "2.Collect data â€“ Get the data you need.\n",
    "\n",
    "3.Clean the data â€“ Handle missing values, errors.\n",
    "\n",
    "4.Explore the data â€“ Check patterns using graphs or stats.\n",
    "\n",
    "5.Preprocess data â€“ Encode categories, scale numbers.\n",
    "\n",
    "6.Split the data â€“ Train/test split.\n",
    "\n",
    "7.Choose a model â€“ Like Linear Regression, Decision Tree, etc.\n",
    "\n",
    "8.Train the model â€“ Fit it on training data.\n",
    "\n",
    "9.Test the model â€“ Check accuracy on test data.\n",
    "\n",
    "10.Improve it â€“ Tune parameters if needed.\n",
    "\n",
    "# 11. Why do we have to perform EDA before fitting a model to the data?\n",
    "\n",
    "**EDA (Exploratory Data Analysis)** is the process of understanding the data before applying any machine learning model.\n",
    "\n",
    "---\n",
    "\n",
    "###  Reasons to Perform EDA:\n",
    "\n",
    "1. **Understand the Data**\n",
    "   - Know what your data looks like (shape, types, range, etc.)\n",
    "\n",
    "2. **Detect Missing Values**\n",
    "   - Identify and handle missing or null values.\n",
    "\n",
    "3. **Find Outliers**\n",
    "   - Spot unusual values that can affect model performance.\n",
    "\n",
    "4. **Discover Relationships**\n",
    "   - Understand how features relate to each other and to the target.\n",
    "\n",
    "5. **Visualize Data**\n",
    "   - Use graphs to spot patterns, trends, or imbalances.\n",
    "\n",
    "6. **Check Data Quality**\n",
    "   - Fix wrong data types, duplicates, and inconsistent entries.\n",
    "\n",
    "7. **Choose Right Features**\n",
    "   - Identify which features are useful and which are not.\n",
    "\n",
    "---\n",
    "\n",
    "### In short:\n",
    "\n",
    "> EDA helps you **clean, understand, and prepare** the data so that the model can **learn better and give accurate results**.\n",
    "\n",
    " # 12. What is correlation?\n",
    "\n",
    "**Correlation** is a statistical measure that shows the **relationship between two variables**.\n",
    "\n",
    "- It tells us whether an **increase or decrease in one variable** is associated with an **increase or decrease in another**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Correlation Values:\n",
    "\n",
    "| Correlation Value | Meaning                         |\n",
    "|-------------------|----------------------------------|\n",
    "| +1                | Perfect positive correlation     |\n",
    "| 0                 | No correlation                   |\n",
    "| -1                | Perfect negative correlation     |\n",
    "\n",
    "---\n",
    "\n",
    "###  In short:\n",
    "\n",
    "> Correlation shows how **two variables move together** â€“ either in the **same direction** (positive) or **opposite direction** (negative).\n",
    "\n",
    "# 13. What does negative correlation mean?\n",
    "\n",
    "**Negative correlation** means that **as one variable increases, the other decreases**.\n",
    "\n",
    "- The variables move in **opposite directions**.\n",
    "- The correlation value is **less than 0**, down to **-1**.\n",
    "\n",
    "---\n",
    "\n",
    "### Example:\n",
    "\n",
    "- As **temperature increases**, **sales of jackets decrease**.\n",
    "- As **exercise time increases**, **body fat percentage may decrease**.\n",
    "\n",
    "---\n",
    "\n",
    "###  In short:\n",
    "\n",
    "> Negative correlation = One goes **up**, the other goes **down**.\n",
    "\n",
    "\n",
    "# 14. How can you find correlation between variables in Python?\n",
    "\n",
    "You can use the `.corr()` function in **Pandas** to find the **correlation between numerical variables**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Example:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'height': [150, 160, 170, 180],\n",
    "    \n",
    "    'weight': [50, 60, 65, 80]\n",
    "}\n",
    "                      \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "print(correlation_matrix)\n",
    "\n",
    "\n",
    "# Visualizing Correlation (Optional):\n",
    " \n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 15. What is causation? Explain difference between correlation and causation with an example. \n",
    "\n",
    "### What is Causation?\n",
    "\n",
    "**Causation** means that **one variable directly affects or causes a change in another**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Correlation vs Causation\n",
    "\n",
    "| Aspect       | Correlation                         | Causation                                |\n",
    "|--------------|-------------------------------------|-------------------------------------------|\n",
    "| Meaning      | Variables move together             | One variable causes the other to change   |\n",
    "| Direction    | No direction implied                | Has a clear cause and effect              |\n",
    "| Proof Needed | Just statistical link               | Needs experiments or strong evidence      |\n",
    "\n",
    "---\n",
    "\n",
    "###  Example:\n",
    "\n",
    "- **Correlation**: Ice cream sales and drowning cases both increase in summer.  \n",
    "  â†’ They are related (correlated) but one does **not cause** the other.\n",
    "\n",
    "- **Causation**: Smoking increases the risk of lung cancer.  \n",
    "  â†’ Smoking is a **cause** of cancer (causation).\n",
    "\n",
    "---\n",
    "\n",
    "###  In short:\n",
    "> - **Correlation** = Things happen **together**  \n",
    "> - **Causation** = One thing **causes** the other\n",
    "\n",
    "# 16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "\n",
    "### What is an Optimizer?\n",
    "\n",
    "An **optimizer** is a method used in machine learning (especially deep learning) to **adjust the model's weights** to reduce the **loss/error** during training.\n",
    "\n",
    "---\n",
    "\n",
    "###  Why is it important?\n",
    "- Optimizers help the model **learn faster** and more **accurately**.\n",
    "- They update weights based on **gradients** from backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "###  Common Types of Optimizers:\n",
    "\n",
    "#### 1. **SGD (Stochastic Gradient Descent)**\n",
    "\n",
    "- Updates weights using a small batch of data.\n",
    "\n",
    "- Simple and fast but may take longer to converge.\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "\n",
    "2. Momentum\n",
    "\n",
    " - Improves SGD by adding a \"velocity\" term to avoid local minima.\n",
    "\n",
    " - Moves faster in the right direction.\n",
    "\n",
    "SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "3. RMSProp\n",
    "\n",
    " - Adapts learning rate for each weight.\n",
    "\n",
    " - Good for recurrent neural networks (RNNs).\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "\n",
    "4. Adam (Adaptive Moment Estimation)\n",
    "\n",
    " - Combines Momentum and RMSProp.\n",
    "\n",
    " - Most widely used, fast and efficient.\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# 17. What is sklearn.linear_model ?\n",
    "\n",
    "`sklearn.linear_model` is a module in **Scikit-learn** that provides **linear models** for **regression** and **classification** tasks.\n",
    "\n",
    "---\n",
    "\n",
    "###  Common Models in `sklearn.linear_model`:\n",
    "\n",
    "| Model                  | Use Case                         |\n",
    "|------------------------|----------------------------------|\n",
    "| `LinearRegression`     | Predicting continuous values     |\n",
    "| `LogisticRegression`   | Binary or multi-class classification |\n",
    "| `Ridge`                | Linear regression with L2 regularization |\n",
    "| `Lasso`                | Linear regression with L1 regularization |\n",
    "| `ElasticNet`           | Combination of L1 and L2 regularization |\n",
    "| `SGDClassifier`        | Large-scale classification using SGD |\n",
    "| `SGDRegressor`         | Large-scale regression using SGD |\n",
    "\n",
    "---\n",
    "\n",
    "###  Example: Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 18. What does model.fit() do? What arguments must be given?\n",
    "\n",
    "### What does `model.fit()` do?\n",
    "\n",
    "The `model.fit()` function is used to **train the machine learning model**.\n",
    "\n",
    "- It **learns patterns** from the training data (`X_train`, `y_train`).\n",
    "- After fitting, the model can **make predictions** on new data.\n",
    "\n",
    "---\n",
    "\n",
    "###  Arguments required:\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    " \n",
    " # Example:\n",
    " \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)  # trains the model\n",
    "\n",
    " In short:\n",
    " \n",
    "model.fit(X, y) trains the model using the input features and target output.\n",
    "\n",
    "# 19. What does model.predict() do? What arguments must be given? \n",
    "\n",
    "### What does `model.predict()` do?\n",
    "\n",
    "`model.predict()` is used to **generate predictions** from a **trained machine learning model**.\n",
    "\n",
    "- It uses the **learned patterns** from `model.fit()` to predict outcomes on **new/unseen data**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Argument:\n",
    "\n",
    "model.predict(X)\n",
    "\n",
    "---\n",
    "\n",
    "X: Input features (new data for which you want predictions)\n",
    "\n",
    "# Example:\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 20. What are continuous and categorical variables?\n",
    "\n",
    "###  Continuous Variables:\n",
    "\n",
    "- These are **numeric values** that can take any value within a range.\n",
    "- \n",
    "- Can be **measured** and have decimals.\n",
    "\n",
    "**Examples:**  \n",
    "\n",
    "- Height (170.5 cm)\n",
    " \n",
    "- Weight (65.2 kg)\n",
    " \n",
    "- Temperature (36.6Â°C)\n",
    "\n",
    "---\n",
    "\n",
    "###  Categorical Variables:\n",
    "\n",
    "- These are **labels or categories** that represent different groups.\n",
    "- \n",
    "- Can be **nominal** (no order) or **ordinal** (with order).\n",
    "\n",
    "**Examples:**  \n",
    "\n",
    "- Gender (Male, Female)\n",
    "  \n",
    "- Education Level (High School, Bachelor, Master)\n",
    " \n",
    "- City (Delhi, Mumbai, Pune)\n",
    "\n",
    "---\n",
    "\n",
    "###  In short:\n",
    "\n",
    "> - **Continuous** = Numbers you can measure\n",
    "\n",
    "> - **Categorical** = Names or groups you can label\n",
    "\n",
    "# 21. What is feature scaling? How does it help in Machine Learning?\n",
    "\n",
    "**Feature Scaling** is the process of **normalizing or standardizing** the range of independent variables (features) in your dataset.\n",
    "\n",
    "- It ensures that all features are **on the same scale**.\n",
    "- \n",
    "- Common ranges: **0 to 1** or **mean = 0, std = 1**\n",
    "\n",
    "---\n",
    "\n",
    "###  Why is Feature Scaling Important?\n",
    "\n",
    "- Some machine learning algorithms (like **KNN**, **SVM**, **Gradient Descent**) are **sensitive to the scale** of features.\n",
    "  \n",
    "- Features with larger values can **dominate** others if not scaled.\n",
    "\n",
    "- Helps the model **converge faster** and perform **better**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Common Scaling Techniques:\n",
    "\n",
    "| Method           | Description                              |\n",
    "|------------------|------------------------------------------|\n",
    "| **Min-Max Scaling** | Scales data to range [0, 1]               |\n",
    "| **Standardization** | Scales data to mean = 0, std = 1          |\n",
    "\n",
    "---\n",
    "\n",
    "###  Example (Min-Max Scaling):\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "In short:\n",
    "\n",
    "Feature scaling makes all features comparable, improves accuracy, and speeds up model training.\n",
    "\n",
    "# 22. How do we perform scaling in Python?\n",
    "\n",
    "We use **scikit-learn**'s preprocessing tools to scale numerical features so that all values are on a similar scale.\n",
    "\n",
    "---\n",
    "\n",
    "###  1. Min-Max Scaling (0 to 1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "### 2. Standard Scaling (Mean = 0, Std = 1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "In short:\n",
    "\n",
    "Use MinMaxScaler or StandardScaler from sklearn.preprocessing to scale features for better model performance.\n",
    "\n",
    "# 23. What is sklearn.preprocessing? \n",
    "\n",
    "`sklearn.preprocessing` is a **module in Scikit-learn** that provides tools to **prepare and clean your data** before training a machine learning model.\n",
    "\n",
    "---\n",
    "\n",
    "###  What Can You Do with It?\n",
    "\n",
    "You can:\n",
    "- **Scale features** (e.g., `MinMaxScaler`, `StandardScaler`)\n",
    "- **Encode categorical data** (e.g., `LabelEncoder`, `OneHotEncoder`)\n",
    "- **Normalize data**\n",
    "- **Handle missing values**\n",
    "\n",
    "---\n",
    "\n",
    "###  Example:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(X)\n",
    "\n",
    "In short:\n",
    "\n",
    "sklearn.preprocessing is used to scale, encode, and clean data before feeding it to a model.\n",
    "\n",
    "\n",
    "# 24. How do we split data for model fitting (training and testing) in Python?\n",
    "\n",
    "We use the `train_test_split()` function from **scikit-learn** to split the dataset into **training** and **testing** parts.\n",
    "\n",
    "---\n",
    "\n",
    "###  Why split the data?\n",
    "\n",
    "- **Training set**: used to train the model.\n",
    "- **Test set**: used to evaluate the model on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "###  Example:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = features, y = target/label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    " Parameters: \n",
    " \n",
    "Parameter\t         Description\n",
    "test_size=0.2\t     20% of data for testing\n",
    "random_state=42    \tEnsures the split is reproducible\n",
    "\n",
    "In short:\n",
    "\n",
    "Use train_test_split() to divide your data into training and testing sets for building and evaluating models.\n",
    "\n",
    "\n",
    "# 25. Explain data encoding?\n",
    "\n",
    "**Data Encoding** is the process of **converting categorical (text) data into numeric form** so that machine learning models can understand and use it.\n",
    "\n",
    "Most ML algorithms work only with **numerical values**, not strings or labels.\n",
    "\n",
    "---\n",
    "\n",
    "###  Why is Encoding Needed?\n",
    "\n",
    "- Categorical data like \"Male\"/\"Female\" or \"Red\"/\"Blue\" must be turned into numbers.\n",
    "- Helps the model interpret and learn from the data.\n",
    "\n",
    "---\n",
    "\n",
    "###  Common Encoding Techniques:\n",
    "\n",
    "| Technique           | Use Case                               |\n",
    "|---------------------|-----------------------------------------|\n",
    "| **Label Encoding**  | For **ordinal** data (ordered categories) |\n",
    "| **One-Hot Encoding**| For **nominal** data (no order)         |\n",
    "| **Ordinal Encoding**| When order matters (manually assigned) |\n",
    "| **Target Encoding** | Uses target variable (e.g., mean)       |\n",
    "| **Frequency Encoding** | Based on count of categories         |\n",
    "\n",
    "---\n",
    "\n",
    "###  Example: One-Hot Encoding\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'color': ['red', 'blue', 'green']})\n",
    "encoded = pd.get_dummies(df['color'])\n",
    "print(encoded)\n",
    "\n",
    "Output:\n",
    "\n",
    "   blue  green  red\n",
    "   \n",
    "0     0      0    1\n",
    "\n",
    "1     1      0    0\n",
    "\n",
    "2     0      1    0\n",
    "\n",
    "In short:\n",
    "\n",
    "Data encoding converts text labels into numbers so machine learning models can use them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b720dc2-f975-4661-96bd-7151af05054d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c4590f1-36b5-4452-98a3-2a2d23783011",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7bf5c4-b7ec-45d3-9da4-1be8715c6aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101c562-725c-49c6-b5e9-8697a4babc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07397a7-b4c1-44b8-a8a0-0d0e00da7923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ec121-0051-4a96-8ca2-8c00316e11ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc9ae7-d58d-4653-b466-f4f313b5c794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
